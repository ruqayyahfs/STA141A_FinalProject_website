---
title: "Discussion and Conclusion"
output: bookdown::html_document2
bibliography: "references.bib"
---

```{css, echo =FALSE}
h1.title {
  font-size: 38px;
  color: mediumslateblue;
  text-align: default;
}
```


# <span style="color: mediumslateblue;">Discussion and Conclusion</span> {#dc}

**Multiple Regression:**
One of the main issues we encountered with every multiple regression model were the high-leverage points. Upon closer inspection of the films that constituted the high-leverage points, we gained some insight into the predictive capabilities of the data set. The movies in the data set with high leverage included: Pulp Fiction, The Dark Knight, The Shawshank Redemption, The Matrix, Forrest Gump, and Inception. Even those who are not avid movie enthusiasts should recognize some of (if not all) the iconic films within this list. 

What our model struggles to predict are those super-hit classic films that have so much influence within the world of entertainment. However, a regression model may give us an idea of IMDB score for average, run-of-the-mill films, based on factors such as budget, number of votes, and runtime. This suggests there are other layers to the art of film-making not quantified in this data set. For instance, other movie metrics such as script quality, actor performance, cinematography, and/or novelty could play a significant role, but these were not captured in the data set that we used 

Our findings suggest these underrepresented qualities are important to the public's perception of films, but needless to say, they may be difficult measures to capture. Perhaps this is why they call it "movie magic!" 

**Hierarchical Clustering:** 
To explore grouping movies with similar attributes together we needed to perform hierarchical clustering using the `daisy()` function with parameter `metric = "gower"`. Our initial issue was attempting to use Euclidean distance to create the clusters. This proved ineffective due to the categorical variables. By using the Gower distance function we were able to work around this and create hierarchical clusters for a the full set of variables and a reduced set of variables. 

We created a function to analyze the mean and proportions of each variable that made up the clusters of each model to explore if the clusters were actually grouping movies with similar attributes together, and to investigate how the clusters differed from one another. Looking at the proportions in particular, we saw that the reduced model had particularly high proportions for `rating` in certain clusters, as well as in `genre`. This is ultimately intuitive as in the presence of fewer variables, these variables had a larger impact on the aggregation of our clusters.

In the Full Hierarchical Clustering model, after returning the list of movies in the red cluster, we can see the movie titles included: Iron Man, Spider-Man: Homecoming, and Wonder Woman. These movies definitely have similarities and would definitely be recommended if any movie was selected first and does correlate with the means and proportions we gathered from our function. However, despite the proportions for variables being higher in the Reduced Variable Hierarchical Clustering model, the movie title list returned from the first cluster has much more variability, for example "The Proposal", a romantic comedy, is being recommended in the same category as "The Twilight Saga: Eclipse", a fantasy movie. This suggests that aside from the "action blockbusters" category that was investigated above, our full model had too much noise to be very effective at establishing meaningful clusters.
